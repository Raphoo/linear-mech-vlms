{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaoFbvMrV5Db"
   },
   "outputs": [],
   "source": [
    "model_names = [\"gemma-4b\", \"llava-13b\", \"llava-7b\", \"llama-11b\", \"internvl-14b\", \"internvl-8b\", \"internvl-2b\", \"internvl-1b\", \"qwen2-2b\", \"qwen-7b\",\"qwen-3b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMHvxH_KaGX7",
    "outputId": "675277cf-770e-493c-ac9c-2f6c3e4efd04"
   },
   "outputs": [],
   "source": [
    "# now get steering res\n",
    "steer_ratio_oneword_lp = dict()\n",
    "steer_ratio_oneword_noise_lp = dict()\n",
    "lenn_deltas = dict()\n",
    "for scale_factor in [5]:\n",
    "  # model_names = [\"qwen-3b\", \"internvl-14b\", \"llava-7b\"]#,\"gemma-12b\"]\n",
    "\n",
    "  steer_ratio_oneword_lp[scale_factor] = dict()\n",
    "  steer_ratio_oneword_noise_lp[scale_factor] = dict()\n",
    "  lenn_deltas[scale_factor] = dict()\n",
    "  for mm in model_names:\n",
    "    steer_ratio_oneword_lp[scale_factor][mm] = {}  # Changed to dict to store by layer number\n",
    "    steer_ratio_oneword_noise_lp[scale_factor][mm] = {}  # Changed to dict\n",
    "    lenn_deltas[scale_factor][mm] = []\n",
    "\n",
    "\n",
    "  def get_logprob_deltas(data, layername, modelname):\n",
    "      out_delts_corr = []\n",
    "      out_delts_wrong = []\n",
    "      og_data = data.get(\"none\", {})\n",
    "      sel_data = data.get(layername, {})\n",
    "      lenn = 0\n",
    "      lenn_bs = 0\n",
    "\n",
    "\n",
    "      belief_swapped = 0\n",
    "      now_wrong = 0\n",
    "      for elt_key in list(sel_data.keys()):\n",
    "\n",
    "        if 'log_prob' in list(sel_data[elt_key].keys()) and 'log_prob' in list(og_data[elt_key].keys()):\n",
    "\n",
    "          v = sel_data[elt_key]['log_prob']\n",
    "          v_og = og_data[elt_key]['log_prob']\n",
    "\n",
    "          # print(v,v_og)\n",
    "\n",
    "          # if (v[0] < -1e3) or (v_og[0] < -1e3) or (v[1] < -1e3) or (v_og[1] < -1e3):\n",
    "          #   # pass\n",
    "          #   print(v,v_og)\n",
    "          # else:\n",
    "\n",
    "          out_delts_wrong.append(v[1] - v_og[1])\n",
    "          out_delts_corr.append(v[0] - v_og[0])\n",
    "          lenn += 1\n",
    "\n",
    "          if (v[1] - v[0]) > 0 :\n",
    "            now_wrong += 1\n",
    "\n",
    "          original_difference = v_og[0] - v_og[1]\n",
    "          new_difference = v[0] - v[1]\n",
    "\n",
    "          if original_difference != 0 and new_difference != 0:\n",
    "            if (new_difference / original_difference) < 0:\n",
    "              # if division is negative, that means belief was swapepd.\n",
    "              belief_swapped += 1\n",
    "            lenn_bs += 1\n",
    "\n",
    "          else:\n",
    "            print(f\"{model_name} - Skipping bc 0\", elt_key)\n",
    "        else:\n",
    "          print(f\"{model_name} - Skipping bc no logprob\", elt_key)\n",
    "      print(\"now wrong == belief swapped?\", now_wrong, belief_swapped)\n",
    "      if lenn_bs == 0:\n",
    "        lenn_bs = 1\n",
    "        print(f\"{model_name} - lenn_bs was 0. \")\n",
    "      if lenn == 0:\n",
    "        lenn = 1\n",
    "        print(f\"{model_name} - lenn was 0. \")\n",
    "\n",
    "      lenn_deltas[scale_factor][model_name].append((lenn_bs, lenn))\n",
    "      # print(sum(out_delts_wrong)/lenn)\n",
    "      return sum(out_delts_corr)/lenn, sum(out_delts_wrong)/lenn, belief_swapped/lenn_bs, now_wrong/lenn\n",
    "\n",
    "  for model_name in model_names:\n",
    "    print(model_name)\n",
    "    json_file = open(f\"metadata/{model_name}_{scale_factor}.json\")\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    # Store results by layer number (not list index) to maintain correspondence\n",
    "    for key_ in data.keys():\n",
    "      if key_ != \"none\" and 'noise' not in key_:\n",
    "        layer_num = int(key_.split('_')[1])\n",
    "        steer_ratio_oneword_lp[scale_factor][model_name][layer_num] = get_logprob_deltas(data, key_, model_name)\n",
    "\n",
    "    for key_ in data.keys():\n",
    "      if key_ != \"none\" and 'noise' in key_:\n",
    "        layer_num = int(key_.split('_')[1])\n",
    "        steer_ratio_oneword_noise_lp[scale_factor][model_name][layer_num] = get_logprob_deltas(data, key_, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJsPZlVe-wth"
   },
   "outputs": [],
   "source": [
    "sll_max = dict()\n",
    "sll_noise_max = dict()\n",
    "scf = 5\n",
    "for modelname in model_names:\n",
    "    # Find layers that exist in BOTH intervention and noise datasets\n",
    "    intervention_layers = set(steer_ratio_oneword_lp[scf][modelname].keys())\n",
    "    noise_layers = set(steer_ratio_oneword_noise_lp[scf][modelname].keys())\n",
    "    common_layers = sorted(intervention_layers & noise_layers)\n",
    "    \n",
    "    # Get intervention values for common layers only\n",
    "    layer_to_val = {layer: steer_ratio_oneword_lp[scf][modelname][layer][2] \n",
    "                    for layer in common_layers}\n",
    "    \n",
    "    # Find top 3 layers by intervention value\n",
    "    top_layers = sorted(layer_to_val.keys(), key=lambda l: layer_to_val[l], reverse=True)[:3]\n",
    "    \n",
    "    # Store top intervention values\n",
    "    vals = [layer_to_val[layer] for layer in top_layers]\n",
    "    sll_max[modelname] = vals\n",
    "    \n",
    "    # Get corresponding noise values at the SAME layer numbers\n",
    "    vals_noise = [steer_ratio_oneword_noise_lp[scf][modelname][layer][2] for layer in top_layers]\n",
    "    sll_noise_max[modelname] = vals_noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "s06noQ6cBvID",
    "outputId": "204c63a4-2795-46f9-ab96-508ed52189ee"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# model_names = sorted(list(steer_ratio_reasoning.keys())) # Sort model names alphabetically\n",
    "num_models = len(model_names)\n",
    "\n",
    "# Prepare data for plotting (Reasoning)\n",
    "change_ratios = [np.mean(sll_max[model_name]) for model_name in model_names]\n",
    "change_ratios_std = [np.std(sll_max[model_name]) for model_name in model_names]\n",
    "\n",
    "\n",
    "# Prepare data for plotting (Reasoning Noise)\n",
    "change_ratios_noise = [np.mean(sll_noise_max[model_name]) for model_name in model_names]\n",
    "change_ratios_noise_std = [np.std(sll_noise_max[model_name]) for model_name in model_names]\n",
    "\n",
    "r1 = np.arange(num_models)\n",
    "bar_height = 0.45\n",
    "r2 = [x + bar_height for x in r1]\n",
    "r3 = [x + bar_height for x in r2]\n",
    "\n",
    "plt.figure(figsize=(8.5,5.5))\n",
    "\n",
    "# Plot for Reasoning\n",
    "plt.barh(r1, change_ratios, height=bar_height, color='skyblue', label='Correct', xerr=change_ratios_std, capsize=2, error_kw={'ecolor': 'cornflowerblue'})\n",
    "plt.barh(r2, change_ratios_noise, height=bar_height, color='peachpuff',  label='Wrong', xerr=change_ratios_noise_std, capsize=2, error_kw={'ecolor': 'sandybrown'})\n",
    "\n",
    "# axes[0].set_xlabel('Average Steer Ratio (Reasoning)', fontweight='bold')\n",
    "plt.yticks([r + bar_height for r in range(num_models)], model_names) #, rotation=90, ha=\"center\")\n",
    "plt.xticks([0.0, 0.2, 0.4, 0.6, 0.8], [0,20,40,60,80])\n",
    "plt.title(f'{scf}x steered - Spatial ID Steering by Model - % Belief Swapped')\n",
    "# axes[0].legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjd08YRP6llR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "og_ratio_reasoning = dict()\n",
    "og_ratio_oneword = dict()\n",
    "\n",
    "def get_ratios_from_layer(data, layername):\n",
    "    sel_data = data.get(layername, {})\n",
    "    # print(sel_data.values())\n",
    "    verdict_dict = {\"correct\":0, \"wrong\":0, \"nonsense\":0}\n",
    "    for elt in sel_data.values():\n",
    "      v = elt['verdict']\n",
    "      verdict_dict[v] += 1\n",
    "\n",
    "    ratio_corr = verdict_dict['correct'] / (verdict_dict['correct'] + verdict_dict['wrong'] + verdict_dict['nonsense'])\n",
    "    ratio_wrong = verdict_dict['wrong'] / (verdict_dict['correct'] + verdict_dict['wrong'] + verdict_dict['nonsense'])\n",
    "    ratio_nonsense = verdict_dict['nonsense'] / (verdict_dict['correct'] + verdict_dict['wrong'] + verdict_dict['nonsense'])\n",
    "\n",
    "    ratio = [ratio_corr, ratio_wrong, ratio_nonsense]\n",
    "\n",
    "    return ratio\n",
    "\n",
    "\n",
    "metadata_dir = \"metadata\"\n",
    "\n",
    "#first populate accuracies\n",
    "for filename in os.listdir(metadata_dir):\n",
    "\n",
    "    if filename.endswith(\"_reasoning.json\"):\n",
    "        model_name = filename.replace(\"_reasoning.json\", \"\")\n",
    "        json_path = os.path.join(metadata_dir, filename)\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            og_ratio_reasoning[model_name] = get_ratios_from_layer(data, \"none\")\n",
    "    elif \"reasoning\" not in filename:\n",
    "\n",
    "        model_name = filename.replace(\".json\", \"\")\n",
    "        json_path = os.path.join(metadata_dir, filename)\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            og_ratio_oneword[model_name] = get_ratios_from_layer(data, \"none\")\n",
    "\n",
    "print(og_ratio_oneword)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YcL_EAiyWF12",
    "dgbtOj9QxDJQ",
    "kWxP_VCLzlrX",
    "SyBPlnzo74qS",
    "CFbZ1WyZ6j0w",
    "cmw3Js55adWv",
    "rsm9OBkTpect",
    "O5aoe9ZbpamR",
    "qV-il7SB-6wH",
    "v_nVn_fzFHZS"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vlm-bind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
