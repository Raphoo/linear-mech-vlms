{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal ID Experiments - Figure 10 Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "MIRROR_SWAP_DIR = Path(\"embeds/mirror_swapping\")\n",
    "STEERING_DIR = Path(\"embeds/temporal_steering\")\n",
    "EMBEDS_DIR = Path(\"embeds\")\n",
    "\n",
    "# Output directory for figures\n",
    "FIG_DIR = Path(\"figures\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Data directories:\")\n",
    "print(f\"  Mirror Swapping: {MIRROR_SWAP_DIR}\")\n",
    "print(f\"  Steering: {STEERING_DIR}\")\n",
    "print(f\"  Embeddings: {EMBEDS_DIR}\")\n",
    "print(f\"\\nFigures will be saved to: {FIG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 10a: Mirror Swapping on Videos\n",
    "\n",
    "Shows the layer-specific effect of swapping object word tokens between normal and reversed videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting utilities\n",
    "from swapping_plotting import plot_coords_across_layers\n",
    "\n",
    "# Load mirror swapping results\n",
    "mirror_swap_results = torch.load(MIRROR_SWAP_DIR / \"mirror_swapping_results.pt\")\n",
    "\n",
    "print(f\"Loaded mirror swapping results for {len(mirror_swap_results)} videos\")\n",
    "\n",
    "# Check data structure\n",
    "sample_key = list(mirror_swap_results.keys())[0]\n",
    "print(f\"Sample key: {sample_key}\")\n",
    "print(f\"Available modalities: {list(mirror_swap_results[sample_key].keys())}\")\n",
    "\n",
    "# Plot all three modalities across layers\n",
    "layers_to_plot = list(range(1, 28))\n",
    "\n",
    "plot_coords_across_layers(\n",
    "    mirror_swap_results,\n",
    "    layers=layers_to_plot,\n",
    "    coords=['text', 'image', 'text-objonly'],\n",
    "    figsize=(10.5, 4),\n",
    "    ylim=[-1, 2],\n",
    "    save_path=FIG_DIR / \"figure_10a_mirror_swapping.png\"\n",
    ")\n",
    "\n",
    "print(\"✓ Figure 10a saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 10b: Temporal ID Grid (PCA Projection)\n",
    "\n",
    "Shows 1D PCA projection of temporal IDs for frames 1-7, with \"Before\" and \"After\" text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_pca(big_embeds_dict, word=None, layer=9, before_emb=None, after_emb=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot 1D PCA projection of temporal embeddings.\n",
    "    \n",
    "    Args:\n",
    "        big_embeds_dict: Dictionary of embeddings (average_embeds_dict format: [layer][frame] -> tensor)\n",
    "        word: Object word (None for average embeddings)\n",
    "        layer: Layer number to visualize\n",
    "        before_emb: Embedding for \"before\" text (shape: hidden_dim)\n",
    "        after_emb: Embedding for \"after\" text (shape: hidden_dim)\n",
    "        save_path: Path to save the figure\n",
    "    \"\"\"\n",
    "    # Collect vectors for the word at the specified layer\n",
    "    if word is None:\n",
    "        frame_nums = sorted(big_embeds_dict[layer].keys())\n",
    "        vectors = torch.stack([\n",
    "            big_embeds_dict[layer][f].to(dtype=torch.float32).cpu()\n",
    "            for f in frame_nums\n",
    "        ])\n",
    "    else:\n",
    "        frame_nums = sorted(big_embeds_dict[word][layer].keys())\n",
    "        vectors = torch.stack([\n",
    "            big_embeds_dict[word][layer][f].to(dtype=torch.float32).cpu()\n",
    "            for f in frame_nums\n",
    "        ])\n",
    "\n",
    "    # Run PCA to get 1D projection\n",
    "    pca = PCA(n_components=1)\n",
    "    pcs = pca.fit_transform(vectors.numpy())  # shape (num_frames, 1)\n",
    "    \n",
    "    # Flip axis if needed: ensure early frames (low index) have lower projection values\n",
    "    # This ensures \"before\" is on the left and \"after\" is on the right\n",
    "    if pcs[0, 0] > pcs[-1, 0]:\n",
    "        pcs = -pcs\n",
    "        pca.components_ = -pca.components_\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    pcs_min, pcs_max = pcs.min(), pcs.max()\n",
    "    pcs_norm = (pcs - pcs_min) / (pcs_max - pcs_min)\n",
    "\n",
    "    # Project before_emb and after_emb if provided\n",
    "    projected_B = projected_A = None\n",
    "    if before_emb is not None:\n",
    "        before_np = before_emb.to(dtype=torch.float32).cpu().numpy()\n",
    "        if before_np.ndim == 1:\n",
    "            before_np = before_np.reshape(1, -1)\n",
    "        projected_B = pca.transform(before_np).squeeze()\n",
    "        projected_B = (projected_B - pcs_min) / (pcs_max - pcs_min)\n",
    "    if after_emb is not None:\n",
    "        after_np = after_emb.to(dtype=torch.float32).cpu().numpy()\n",
    "        if after_np.ndim == 1:\n",
    "            after_np = after_np.reshape(1, -1)\n",
    "        projected_A = pca.transform(after_np).squeeze()\n",
    "        projected_A = (projected_A - pcs_min) / (pcs_max - pcs_min)\n",
    "\n",
    "    # Plot\n",
    "    colors = plt.get_cmap(\"rainbow\")(np.linspace(0, 1, len(frame_nums)))\n",
    "    plt.figure(figsize=(10, 1.5))\n",
    "\n",
    "    for i, val in enumerate(pcs_norm):\n",
    "        plt.scatter(val, 0, color=colors[i], label=f\"Frame {frame_nums[i]}\", s=80)\n",
    "\n",
    "    if projected_B is not None:\n",
    "        plt.scatter(projected_B, 0, color='black', marker='$B$', s=120, label='$B$ (Before)')\n",
    "\n",
    "    if projected_A is not None:\n",
    "        plt.scatter(projected_A, 0, color='black', marker='$A$', s=150, label='$A$ (After)')\n",
    "\n",
    "    word_label = word if word else \"Average\"\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"First Principal Component\")\n",
    "    plt.title(f'1D PCA of {word_label} Embeddings at Layer {layer}\\nVar explained: {pca.explained_variance_ratio_[0]:.2f}')\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_[0]:.4f}\")\n",
    "    return pca.explained_variance_ratio_[0]\n",
    "\n",
    "\n",
    "# Load temporal embeddings\n",
    "temporal_data = torch.load(EMBEDS_DIR / \"temporal_ids.pt\")\n",
    "big_embeds_dict = temporal_data[\"big_embeds_dict\"]\n",
    "average_embeds_dict = temporal_data[\"average_embeds_dict\"]\n",
    "\n",
    "print(f\"Loaded embeddings for {len(big_embeds_dict)} objects\")\n",
    "print(f\"Layers available: {sorted(average_embeds_dict.keys())}\")\n",
    "\n",
    "# Load text embeddings for \"before\" and \"after\" if available\n",
    "text_embeds_path = EMBEDS_DIR / \"text_embeddings.pt\"\n",
    "before_hidden = None\n",
    "after_hidden = None\n",
    "\n",
    "if text_embeds_path.exists():\n",
    "    text_embeds = torch.load(text_embeds_path)\n",
    "    before_hidden = text_embeds.get(\"before_hidden\")\n",
    "    after_hidden = text_embeds.get(\"after_hidden\")\n",
    "    print(\"Loaded text embeddings for 'before' and 'after'\")\n",
    "else:\n",
    "    print(\"Text embeddings not found - plotting without before/after markers\")\n",
    "\n",
    "# Plot for selected layer\n",
    "layer_to_plot = 12\n",
    "before_emb = before_hidden[layer_to_plot] if before_hidden else None\n",
    "after_emb = after_hidden[layer_to_plot] if after_hidden else None\n",
    "\n",
    "plot_1d_pca(\n",
    "    average_embeds_dict,\n",
    "    word=None,\n",
    "    layer=layer_to_plot,\n",
    "    before_emb=before_emb,\n",
    "    after_emb=after_emb,\n",
    "    save_path=FIG_DIR / \"figure_10b_temporal_id_grid.png\"\n",
    ")\n",
    "print(\"✓ Figure 10b saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 10c: Temporal ID Steering\n",
    "\n",
    "Shows how steering with different temporal IDs affects model beliefs about \"before\" vs \"after\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load steering results (.pt format from temporal_steering.py)\n",
    "# Structure: big_dict[(filename, true_before)][id1][layer] = {'delta_before': tensor, 'delta_after': tensor}\n",
    "steering_results = torch.load(STEERING_DIR / \"steering_results.pt\")\n",
    "\n",
    "print(f\"Loaded steering results for {len(steering_results)} videos\")\n",
    "\n",
    "# Count how many have true_before=True vs False\n",
    "count_true = sum(1 for k in steering_results if k[1] == True)\n",
    "count_false = sum(1 for k in steering_results if k[1] == False)\n",
    "print(f\"  true_before=True (original answer is 'before'): {count_true}\")\n",
    "print(f\"  true_before=False (original answer is 'after'): {count_false}\")\n",
    "\n",
    "# Helper functions based on steering_plotting.py\n",
    "x_labels = list(range(1, 8))  # Intervention IDs 1-7\n",
    "x_vals = list(range(7))\n",
    "\n",
    "def dict_to_lists(d):\n",
    "    return [d[k] for k in x_labels]\n",
    "\n",
    "def compute_mean_std_by_condition(big_dict, layer, answer_side):\n",
    "    \"\"\"\n",
    "    Computes means and stds for 'delta_before' and 'delta_after' given a specified answer_side (True/False).\n",
    "    \n",
    "    answer_side=True means true_before=True, i.e., original correct answer is \"before\"\n",
    "    answer_side=False means true_before=False, i.e., original correct answer is \"after\"\n",
    "    \n",
    "    Returns: means_before, stds_before, means_after, stds_after (as lists ordered by x_labels)\n",
    "    \"\"\"\n",
    "    collect_before = {k: [] for k in x_labels}\n",
    "    collect_after = {k: [] for k in x_labels}\n",
    "    \n",
    "    for kkey in big_dict:\n",
    "        # kkey = (filename, true_before)\n",
    "        if kkey[1] == answer_side:\n",
    "            for id1 in x_labels:\n",
    "                if id1 in big_dict[kkey]:\n",
    "                    if layer in big_dict[kkey][id1]:\n",
    "                        data = big_dict[kkey][id1][layer]\n",
    "                        collect_before[id1].append(data['delta_before'])\n",
    "                        collect_after[id1].append(data['delta_after'])\n",
    "    \n",
    "    means_before, stds_before = {}, {}\n",
    "    means_after, stds_after = {}, {}\n",
    "    \n",
    "    for id1 in x_labels:\n",
    "        if collect_before[id1]:\n",
    "            v_before = torch.stack(collect_before[id1])\n",
    "            v_after = torch.stack(collect_after[id1])\n",
    "            means_before[id1] = torch.mean(v_before).item()\n",
    "            stds_before[id1] = torch.std(v_before).item()\n",
    "            means_after[id1] = torch.mean(v_after).item()\n",
    "            stds_after[id1] = torch.std(v_after).item()\n",
    "        else:\n",
    "            means_before[id1] = 0\n",
    "            stds_before[id1] = 0\n",
    "            means_after[id1] = 0\n",
    "            stds_after[id1] = 0\n",
    "    \n",
    "    return (\n",
    "        dict_to_lists(means_before),\n",
    "        dict_to_lists(stds_before),\n",
    "        dict_to_lists(means_after),\n",
    "        dict_to_lists(stds_after)\n",
    "    )\n",
    "\n",
    "\n",
    "def print_values(layer, label, data):\n",
    "    m_before, _, m_after, _ = data\n",
    "\n",
    "    print(f\"\\n=== Layer {layer} — Original: {label} ===\")\n",
    "    print(\"| Intervention | mean ΔP('before') | mean ΔP('after') | before - after |\")\n",
    "    print(\"|-------------|------------------|------------------|----------------|\")\n",
    "\n",
    "    for interv, mb, ma in zip(x_labels, m_before, m_after):\n",
    "        diff = mb - ma\n",
    "        print(f\"| {interv} | {mb:+.4f} | {ma:+.4f} | {diff:+.4f} |\")\n",
    "\n",
    "\n",
    "def plot_single_condition(ax, data, layer, condition_label):\n",
    "    \"\"\"Plot a single condition (before or after) on one axis.\"\"\"\n",
    "    m_before, s_before, m_after, s_after = data\n",
    "    \n",
    "    ax.plot(x_vals, m_after, label=\"ΔP('after')\")\n",
    "    ax.fill_between(x_vals, [m-s for m,s in zip(m_after, s_after)],\n",
    "                    [m+s for m,s in zip(m_after, s_after)], alpha=0.3)\n",
    "    ax.plot(x_vals, m_before, label=\"ΔP('before')\")\n",
    "    ax.fill_between(x_vals, [m-s for m,s in zip(m_before, s_before)],\n",
    "                    [m+s for m,s in zip(m_before, s_before)], alpha=0.3)\n",
    "    ax.set_xticks(x_vals)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_ylabel(\"Change in Log Prob\")\n",
    "    ax.set_xlabel(\"Intervention ID on subject\")\n",
    "    ax.set_title(f\"Layer {layer} — Original: {condition_label}\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_all_layers(univ, layers=[13], w1=\"before\", w2=\"after\"):\n",
    "    fig, axes = plt.subplots(len(layers), 2, figsize=(10, 3 * len(layers)))\n",
    "    \n",
    "    # Handle single layer case\n",
    "    if len(layers) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, layer in enumerate(layers):\n",
    "        # answer_side=True means original correct answer is \"before\"\n",
    "        # answer_side=False means original correct answer is \"after\"\n",
    "        data_before = compute_mean_std_by_condition(univ, layer, answer_side=True)\n",
    "        data_after = compute_mean_std_by_condition(univ, layer, answer_side=False)\n",
    "        \n",
    "        # Print values\n",
    "        print_values(layer, w1, data_before)\n",
    "        print_values(layer, w2, data_after)\n",
    "        \n",
    "        ax_left, ax_right = axes[i]\n",
    "        # Left subplot: Original answer is \"before\" (true_before=True)\n",
    "        plot_single_condition(ax_left, data_before, layer, w1)\n",
    "        # Right subplot: Original answer is \"after\" (true_before=False)\n",
    "        plot_single_condition(ax_right, data_after, layer, w2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"figure_10c_temporal_steering.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(FIG_DIR / \"figure_10c_temporal_steering.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot for layer 13\n",
    "plot_all_layers(steering_results, layers=[13])\n",
    "print(\"✓ Figure 10c saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm-bind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
